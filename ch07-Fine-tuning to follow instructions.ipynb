{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6409f3e6",
   "metadata": {},
   "source": [
    "# 7 Fine-tuning to follow instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6acf9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.3.4\n",
      "matplotlib version: 3.10.7\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.9.0\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9068c5e",
   "metadata": {},
   "source": [
    "## 7.2 Preparing a dataset for supervised instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02787de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "030a5b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Identify the correct spelling of the following word.',\n",
       " 'input': 'Ocassion',\n",
       " 'output': \"The correct spelling is 'Occasion.'\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f4552cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"What is an antonym of 'complicated'?\",\n",
       " 'input': '',\n",
       " 'output': \"An antonym of 'complicated' is 'simple'.\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "098f469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff271f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIdentify the correct spelling of the following word.\\n\\n### Input:\\nOcassion'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_input(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f895445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n"
     ]
    }
   ],
   "source": [
    "print(format_input(data[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3418300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdafc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f486bc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7e128",
   "metadata": {},
   "source": [
    "## 7.3 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e5b12",
   "metadata": {},
   "source": [
    "We pad on batch basis (to the longest element in the batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99a4d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenized texts\n",
    "        self.encoded_text = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_text.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_text[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88d62628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49be7a",
   "metadata": {},
   "source": [
    "We define a collate function which determines a set of operation we want the dataloader to perform on each batch when its iterating over batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "893a0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * ((batch_max_length) - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9712c3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a01707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * ((batch_max_length) - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51e55952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs_tensor, targets_tensor = custom_collate_draft_2(batch)\n",
    "print(inputs_tensor)\n",
    "print(targets_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37e022ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * ((batch_max_length) - len(new_item))\n",
    "        )\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # if len(targets) > (len(item) + 1):\n",
    "        #     targets[:-(len(targets) - (len(item) + 1))] = \n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "333f1a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs_tensor, targets_tensor = custom_collate(batch)\n",
    "print(inputs_tensor)\n",
    "print(targets_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fd5384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d90bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67ef85e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b0f83",
   "metadata": {},
   "source": [
    "## 7.4 Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57a47aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2996e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a6b8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size, collate_fn=customized_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e392adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcfb6993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a966b0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
       "         1573,   705, 15103,  6985,  4458,   198,   198, 21017, 18261,    25,\n",
       "          198,  3347,   318,   845, 47628,   290,  1464, 13831,  3241,   284,\n",
       "         3307,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "596ecdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
       "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
       "        46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,  1573,\n",
       "          705, 15103,  6985,  4458,   198,   198, 21017, 18261,    25,   198,\n",
       "         3347,   318,   845, 47628,   290,  1464, 13831,  3241,   284,  3307,\n",
       "           13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d896c5b",
   "metadata": {},
   "source": [
    "## 7.5 Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ee988e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 23:44:39.181065: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 23:44:39.922408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-30 23:45:04.703824: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 19.4kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.36MiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 15.8kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [02:02<00:00, 11.6MiB/s]\n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 2.69MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 2.58MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.04MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "490be253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f869adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "213f2496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d516bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f5486",
   "metadata": {},
   "source": [
    "## 7.6 Fintuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff4786e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "590557ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259093284606935\n",
      "Validation loss: 3.7619336605072022\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5107180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.304, Val loss 0.673\n",
      "Ep 1 (Step 000005): Train loss 0.284, Val loss 0.695\n",
      "Ep 1 (Step 000010): Train loss 0.319, Val loss 0.704\n",
      "Ep 1 (Step 000015): Train loss 0.305, Val loss 0.682\n",
      "Ep 1 (Step 000020): Train loss 0.344, Val loss 0.700\n",
      "Ep 1 (Step 000025): Train loss 0.315, Val loss 0.713\n",
      "Ep 1 (Step 000030): Train loss 0.352, Val loss 0.717\n",
      "Ep 1 (Step 000035): Train loss 0.277, Val loss 0.714\n",
      "Ep 1 (Step 000040): Train loss 0.290, Val loss 0.706\n",
      "Ep 1 (Step 000045): Train loss 0.332, Val loss 0.716\n",
      "Ep 1 (Step 000050): Train loss 0.324, Val loss 0.711\n",
      "Ep 1 (Step 000055): Train loss 0.276, Val loss 0.724\n",
      "Ep 1 (Step 000060): Train loss 0.276, Val loss 0.718\n",
      "Ep 1 (Step 000065): Train loss 0.275, Val loss 0.701\n",
      "Ep 1 (Step 000070): Train loss 0.297, Val loss 0.690\n",
      "Ep 1 (Step 000075): Train loss 0.261, Val loss 0.673\n",
      "Ep 1 (Step 000080): Train loss 0.259, Val loss 0.678\n",
      "Ep 1 (Step 000085): Train loss 0.273, Val loss 0.672\n",
      "Ep 1 (Step 000090): Train loss 0.261, Val loss 0.658\n",
      "Ep 1 (Step 000095): Train loss 0.287, Val loss 0.648\n",
      "Ep 1 (Step 000100): Train loss 0.267, Val loss 0.649\n",
      "Ep 1 (Step 000105): Train loss 0.253, Val loss 0.654\n",
      "Ep 1 (Step 000110): Train loss 0.262, Val loss 0.668\n",
      "Ep 1 (Step 000115): Train loss 0.250, Val loss 0.676\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the opposite of 'cold'?\n",
      "Ep 2 (Step 000120): Train loss 0.221, Val loss 0.706\n",
      "Ep 2 (Step 000125): Train loss 0.232, Val loss 0.746\n",
      "Ep 2 (Step 000130): Train loss 0.261, Val loss 0.735\n",
      "Ep 2 (Step 000135): Train loss 0.262, Val loss 0.735\n",
      "Ep 2 (Step 000140): Train loss 0.233, Val loss 0.735\n",
      "Ep 2 (Step 000145): Train loss 0.224, Val loss 0.733\n",
      "Ep 2 (Step 000150): Train loss 0.232, Val loss 0.743\n",
      "Ep 2 (Step 000155): Train loss 0.245, Val loss 0.752\n",
      "Ep 2 (Step 000160): Train loss 0.211, Val loss 0.735\n",
      "Ep 2 (Step 000165): Train loss 0.230, Val loss 0.723\n",
      "Ep 2 (Step 000170): Train loss 0.224, Val loss 0.725\n",
      "Ep 2 (Step 000175): Train loss 0.222, Val loss 0.724\n",
      "Ep 2 (Step 000180): Train loss 0.207, Val loss 0.724\n",
      "Ep 2 (Step 000185): Train loss 0.216, Val loss 0.719\n",
      "Ep 2 (Step 000190): Train loss 0.229, Val loss 0.719\n",
      "Ep 2 (Step 000195): Train loss 0.217, Val loss 0.722\n",
      "Ep 2 (Step 000200): Train loss 0.190, Val loss 0.726\n",
      "Ep 2 (Step 000205): Train loss 0.218, Val loss 0.736\n",
      "Ep 2 (Step 000210): Train loss 0.222, Val loss 0.731\n",
      "Ep 2 (Step 000215): Train loss 0.205, Val loss 0.732\n",
      "Ep 2 (Step 000220): Train loss 0.201, Val loss 0.730\n",
      "Ep 2 (Step 000225): Train loss 0.228, Val loss 0.724\n",
      "Ep 2 (Step 000230): Train loss 0.213, Val loss 0.711\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
      "Training completed in 0.48 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=5, eval_iter=5, start_context=format_input(val_data[0]), tokenizer=tokenizer)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e6068e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d21b5",
   "metadata": {},
   "source": [
    "## 7.7 Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a6db9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus or stratus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d236436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:14<00:00,  7.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef13c06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Rewrite the sentence using a simile.',\n",
       " 'input': 'The car is very fast.',\n",
       " 'output': 'The car is as fast as lightning.',\n",
       " 'model_response': 'The car is as fast as a cheetah.'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dac4967f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda83ec",
   "metadata": {},
   "source": [
    "## 7.8 Evaluating the finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea16c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
